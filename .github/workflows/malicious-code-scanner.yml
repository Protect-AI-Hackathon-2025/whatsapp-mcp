name: Malicious Code Scanner

on: [push]

jobs:
  scan-for-malicious-code:
    name: Scan Commit for Malicious Code
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install OpenAI CLI
        run: pip install openai

      - name: Get Git Diff
        id: get_diff
        run: |
          git fetch --unshallow || true
          git fetch origin main || true

          echo "üîÑ Trying origin/main merge base diff..."
          if git merge-base origin/main HEAD >/dev/null 2>&1; then
            git diff $(git merge-base origin/main HEAD)..HEAD > diff.txt
          elif git rev-parse HEAD^ >/dev/null 2>&1; then
            echo "‚ö†Ô∏è No merge base. Falling back to HEAD^ (immediate parent)."
            git diff HEAD^ > diff.txt
          else
            echo "üö´ No merge base or parent commit. Creating placeholder diff."
            echo "# No previous commit to diff against." > diff.txt
          fi

          echo "üîç Git Diff Output:"
          cat diff.txt

      - name: Analyze with OpenAI LLM
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python3 - <<EOF
          import os
          from openai import OpenAI

          client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

          with open("diff.txt") as f:
              code = f.read()

          print("üîß Loaded diff content:")
          print(code)

          prompt = (
              "You are a cybersecurity expert specializing in malware detection and secure DevOps practices.\n\n"
              "Analyze the following code changes for signs of malicious behavior, focusing on:\n"
              "1. Attempts to exfiltrate data (e.g., sending to external servers, writing sensitive data to disk)\n"
              "2. Unauthorized access to system resources or environment variables\n"
              "3. Introduction of hardcoded credentials or API keys\n"
              "4. Suspicious use of eval, exec, subprocess, or shell commands\n"
              "5. Abuse of networking, file I/O, or cryptographic libraries\n"
              "6. Unusual changes in authentication or authorization logic\n"
              "7. Unexpected telemetry, tracking, or logging behavior\n"
              "8. Creation of persistence mechanisms or backdoors\n"
              "9. Obfuscation or stealth techniques (e.g., base64, encoded strings)\n\n"
              "For each issue found, provide:\n"
              "1. Description\n"
              "2. Severity (Critical, High, Medium, Low, Info)\n"
              "3. Code line(s) if possible\n"
              "4. Impact\n\n"
              "Format the output as a JSON array of objects with this structure:\n\n"
              "[\n"
              "  {\n"
              '    \"vulnerability_type\": \"Type\",\n'
              '    \"description\": \"Description\",\n'
              '    \"severity\": \"Severity\",\n'
              '    \"line_numbers\": [line numbers],\n'
              '    \"impact\": \"Impact\"\n'
              "  }\n"
              "]\n\n"
              "If nothing suspicious is found, return an empty array: []\n\n"
              "Here are the code changes:\n\n"
              "```diff\n"
              + code +
              "\n```"
          )

          response = client.chat.completions.create(
              model="gpt-4",
              messages=[{"role": "user", "content": prompt}]
          )

          print("üîç OpenAI Analysis Output:")
          print(response.choices[0].message.content)
          EOF
